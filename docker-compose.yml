services:
  mysql:
    container_name: legacy-mysql
    image: mysql:5.7
    platform: linux/x86_64
    restart: always
    attach: false
    command: --transaction-isolation=READ-COMMITTED --log-bin=binlog --binlog-format=ROW --server-id=1
    environment:
      MYSQL_DATABASE: 'db'
      MYSQL_USER: 'user'
      MYSQL_PASSWORD: 'password'
      MYSQL_ROOT_PASSWORD: 'password'
    ports:
    - '3306:3306'
    expose:
    - '3306'
    volumes:
    - my_db:/var/lib/mysql
  jobmanager:
    container_name: jobmanager
    platform: linux/arm64/v8
    hostname: jobmanager
    build:
      context: ./images/pyflink
      dockerfile: .Dockerfile
    ports:
    - "8081:8081"
    command: jobmanager
    attach: false
    restart: always
    volumes:
    - ./datasets:/opt/flink/datasets
    - ./flink_checkpoints:/opt/flink/checkpoints
    environment:
    - |
      FLINK_PROPERTIES=
      jobmanager.rpc.address: jobmanager
      jobmanager.memory.process.size: 2500m
      jobstore.max-capacity: 8
      jobstore.type: file
      state.checkpoint-storage: filesystem
      state.checkpoints.dir: file:///opt/flink/checkpoints
      state.checkpoints.num-retained: 3
      execution.checkpointing.interval: 1000
      execution.checkpointing.min-pause: 500
      execution.checkpointing.tolerable-failed-checkpoints: 2 
      execution.checkpointing.timeout: 60000
      execution.checkpointing.unaligned.enabled: true
      execution.checkpointing.externalized-checkpoint-retention: DELETE_ON_CANCELLATION
      rest.flamegraph.enabled: true
  taskmanager:
    container_name: taskmanager
    platform: linux/arm64/v8
    attach: false
    restart: always
    build:
      context: ./images/pyflink
      dockerfile: .Dockerfile
    depends_on:
    - jobmanager
    command: taskmanager
    volumes:
    - ./datasets:/opt/flink/datasets
    scale: 1
    environment:
    - |
      FLINK_PROPERTIES=
      jobmanager.rpc.address: jobmanager
      taskmanager.numberOfTaskSlots: 8
      parallelism.default: 1
      taskmanager.memory.process.size: 11500m
      taskmanager.memory.flink.size: 10000m
      taskmanager.memory.managed.size: 1500m
      taskmanager.memory.task.heap.size: 1800m
      taskmanager.memory.task.off-heap.size: 1000m
      taskmanager.memory.framework.off-heap.size: 2700m
      taskmanager.memory.framework.heap.size: 1800m
      taskmanager.memory.jvm-metaspace.size: 1200m
    links:
      - mysql:db
  pyflink-client:
    platform: linux/arm64/v8
    container_name: pyflink-client
    depends_on:
    - taskmanager
    build:
      context: ./images/pyflink
      dockerfile: .Dockerfile
    command: >
      bash -c  "python ./project/main.py"
    environment:
    - DATABASE=production
    - DB_HOST=mysql
    - DB_USER=root
    - DB_PASSWORD=password
    - ENV=development
    - DB_CONFIG=/opt/flink/project/configs/database.json
    - PROCESS_CONFIG_PATH=/opt/flink/project/configs/process_config.json
    - DEBEZIUM_CONFIG_FILE_PATH=/opt/flink/project/configs/debezium.json
    - SCRIPTS_PATH_DIR=/opt/flink/project/scripts
    - CONNECT_URL=http://kafka-connect:8083
    - KAFKA_SERVERS=${CCLOUD_BROKER_HOST}:9092
    - CONFLUENT_KAFKA_API_KEY=${CCLOUD_API_KEY}
    - CONFLUENT_KAFKA_API_SECRET=${CCLOUD_API_SECRET}
    - ELASTICSEARCH_URL=elasticsearch:9200
    - MINIO_HOST=minio:9000
    - MINIO_USER=bar
    - MINIO_PASSWORD=Strong#Pass#2022
    - SINK_BUCKET=raw-zone
    volumes:
    - ./flink_process:/opt/flink/ops
    - ./jars:/opt/flink/opt
    - ./datasets:/opt/flink/datasets
    - .:/opt/flink/project
    - ./flink_checkpoints:/opt/flink/checkpoints
    scale: 1
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    attach: false
    container_name: elasticsearch
    platform: linux/amd64
    environment:
    - xpack.security.enabled=false
    - discovery.type=single-node
    - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    ports:
    - 9200:9200
    - 9300:9300
    volumes:
    - ./elasticsearch_vol:/usr/share/elasticsearch/data
  kibana:
    container_name: kibana
    attach: false
    image: docker.elastic.co/kibana/kibana:8.12.1
    environment:
    - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
    - 5601:5601
    depends_on:
    - elasticsearch
  minio:
    container_name: minio
    image: minio/minio
    attach: false
    ports:
    - "9000:9000"
    - "9001:9001"
    volumes:
    - minio_storage:/data
    environment:
      MINIO_ROOT_USER: bar
      MINIO_ROOT_PASSWORD: Strong#Pass#2022
    command: server --console-address ":9001" /data
  neo:
    container_name: neo4j
    attach: false
    image: neo4j:latest
    environment:
    - NEO4J_AUTH=none
    ports: 
    - 7474:7474
    - 7687:7687
    volumes:
    - neo4j_data:/data/
  kafka-connect-onpremis:
    image: confluentinc/cp-kafka-connect:7.5.3
    container_name: kafka-connect
    platform: linux/amd64
    attach: false
    restart: always
    ports:
      - 8083:8083
    healthcheck:
      test: curl http://kafka-connect:8083/ || exit 1
      start_period: 4m
      interval: 30s
      timeout: 10s
      retries: 1
    environment:
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CUB_KAFKA_TIMEOUT: 300
      CONNECT_BOOTSTRAP_SERVERS: "${CCLOUD_BROKER_HOST}:9092"
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect-01'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect-group-01
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-01-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-01-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-01-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "${CCLOUD_SCHEMA_REGISTRY_URL}"
      CONNECT_KEY_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "${CCLOUD_SCHEMA_REGISTRY_URL}"
      CONNECT_VALUE_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: "USER_INFO"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: "${CCLOUD_SCHEMA_REGISTRY_API_KEY}:${CCLOUD_SCHEMA_REGISTRY_API_SECRET}"
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_LOG4J_ROOT_LOGLEVEL: 'INFO'
      CONNECT_LOG4J_LOGGERS: 'org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '3'
      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_SASL_MECHANISM: "PLAIN"
      CONNECT_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_CONSUMER_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_CONSUMER_SASL_MECHANISM: "PLAIN"
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_PRODUCER_SECURITY_PROTOCOL: "SASL_SSL"
      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      CONNECT_PRODUCER_SASL_MECHANISM: "PLAIN"
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${CCLOUD_API_KEY}\" password=\"${CCLOUD_API_SECRET}\";"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components'
    command: > 
      bash -c "
      confluent-hub install --no-prompt debezium/debezium-connector-mysql:2.4.2 && \
      /etc/confluent/docker/run"
volumes:
  my_db:
  minio_storage:
  elasticsearch_vol:
  flink_checkpoints:
  neo4j_data: